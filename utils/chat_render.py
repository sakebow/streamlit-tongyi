# handler.py
from __future__ import annotations
import re, time
import streamlit as st
from collections.abc import Iterable as AbcIterable
from typing import Any, Sequence, Iterator, Tuple, Optional
from collections.abc import Iterator

from langchain.callbacks.base import BaseCallbackHandler
from langchain_core.messages.base import BaseMessageChunk, BaseMessage

from utils.page_content import get_messages_container

_THINK_RE = re.compile(r"<think>(.*?)</think>", re.S)


class ChatRenderer:
    """å…¼å®¹ LangChain/LangGraph çš„æµå¼æ¸²æŸ“å™¨ï¼ˆexpander + chat_messageï¼‰"""

    def __init__(
        self,
        role: str,
        save: bool = True,
        typing_delay: float = 0.02,
        state_path: "Sequence[str] | str" = "dashscope",
    ):
        self.role = role
        self.save = save
        self.typing_delay = typing_delay
        self.state_path = state_path

        with st.chat_message(role):
            self.answer_holder = st.empty()

        self.expander = None
        self.think_holder = None
        self._buffer = ""

    # ===== å…¬å…±æ¥å£ =====
    def render(
        self,
        msg_stream: "str | BaseMessage | BaseMessageChunk | AbcIterable",
        *,
        nodes: "set[str] | None" = None,  # å¯é€‰ï¼šåªæ˜¾ç¤ºè¿™äº›èŠ‚ç‚¹çš„ token
        tags: "set[str] | None" = None,  # å¯é€‰ï¼šåªæ˜¾ç¤ºå¸¦è¿™äº› tag çš„ token
    ):
        """æŠŠå„ç§è¾“å…¥ç»Ÿä¸€æµå¼æ¸²æŸ“åˆ° UIã€‚"""
        for text, meta in self._iter_tokens(msg_stream):
            # å¯é€‰è¿‡æ»¤ï¼šæŒ‰èŠ‚ç‚¹/æ ‡ç­¾è¿‡æ»¤å¹¶å‘è¾“å‡ºï¼Œé¿å…ä¸²æµäº¤å‰
            if nodes and (meta or {}).get("langgraph_node") not in nodes:
                continue
            if tags and not (tags <= set((meta or {}).get("tags", []))):
                continue

            if text:
                self._update(text)
                if self.typing_delay:
                    time.sleep(self.typing_delay)
        if self.save:
            get_messages_container(self.state_path).append(
                {"role": self.role, "content": self._buffer}
            )
        print(self.role)
        print(get_messages_container(self.state_path))
        print("\n")

    # ===== å†…éƒ¨ï¼šæŠŠä»»æ„è¾“å…¥è¿­ä»£æˆ (text, metadata) =====
    def _iter_tokens(
        self, stream: "str | BaseMessage | BaseMessageChunk | AbcIterable"
    ) -> Iterator[Tuple[str, Optional[dict]]]:
        # 1) å•æ¬¡å¯¹è±¡ï¼šstr / BaseMessage / BaseMessageChunk
        if isinstance(stream, (str, BaseMessage, BaseMessageChunk)):
            text = self._to_text(stream)
            if text:
                yield text, None
            return

        # 2) å¯è¿­ä»£æµï¼ˆLangGraph/è‡ªå®šä¹‰ï¼‰
        if isinstance(stream, AbcIterable):
            for item in stream:
                meta = None
                chunk = item

                # LangGraph messages æ¨¡å¼ï¼š (message_chunk, metadata)
                if isinstance(item, tuple) and len(item) == 2:
                    chunk, meta = item

                # å°‘æ•°æƒ…å†µä¸‹ä¼šæ˜¯ [BaseMessageChunk, ...] çš„åˆ—è¡¨
                if (
                    isinstance(chunk, (list, tuple))
                    and chunk
                    and isinstance(chunk[0], BaseMessageChunk)
                ):
                    for c in chunk:
                        text = self._to_text(c)
                        if text:
                            yield text, meta
                    continue

                text = self._to_text(chunk)
                if text:
                    yield text, meta
            return

        raise TypeError("ä¸æ”¯æŒçš„æ¶ˆæ¯ç±»å‹")

    # ===== å†…éƒ¨ï¼šæŠŠå„ç§ Message / Chunk å–å‡ºå¯æ˜¾ç¤ºçš„çº¯æ–‡æœ¬ =====
    def _to_text(self, m: "str | BaseMessage | BaseMessageChunk") -> str:
        if isinstance(m, str):
            return m
        if isinstance(m, (BaseMessage, BaseMessageChunk)):
            c = getattr(m, "content", "")
            if isinstance(c, str):
                return c
            # content-blocksï¼ˆä¾‹å¦‚ Anthropicï¼‰ï¼šä»…æå– type=='text'
            if isinstance(c, list):
                parts = []
                for b in c:
                    if isinstance(b, dict) and b.get("type") == "text" and "text" in b:
                        parts.append(b["text"])
                return "".join(parts)
        return ""

    # ===== å†…éƒ¨ï¼šåˆ·æ–° UI =====
    def _update(self, new_text: str):
        if not new_text:
            return
        self._buffer += new_text

        # èšåˆæ‰€æœ‰ <think> æ®µè½
        think_parts = "\n".join(_THINK_RE.findall(self._buffer))
        answer_text = _THINK_RE.sub("", self._buffer).strip() or " "

        if think_parts and self.expander is None:
            self.expander = st.expander("ğŸ¤” æ€è€ƒè¿‡ç¨‹", expanded=False)
            self.think_holder = self.expander.empty()

        if self.think_holder is not None:
            self.think_holder.markdown(think_parts)
        self.answer_holder.markdown(answer_text)


# chat_render_callback
class ChatRenderCallbackHandler(BaseCallbackHandler):
    """æŠŠ LLM æµå¼ token æ¸²æŸ“åˆ° Streamlitï¼ŒåŒå®¹å™¨åˆ†æµã€‚"""

    def __init__(
        self,
        role: str = "assistant",
        save: bool = True,
        label: str = "ğŸ¤” æ€è€ƒè¿‡ç¨‹",
        state_path: Sequence[str] | str = "dashscope",
    ):
        super().__init__()
        self.role = role
        self.save = save
        self.label = label

        # UI å ä½ï¼šåªæœ‰ answer å…ˆå ä½ï¼Œ<think> åŠ¨æ€ç”Ÿæˆ
        with st.chat_message(role):
            self.answer_holder = st.empty()

        self.expander = None
        self.think_holder = None

        # ç´¯ç§¯å®Œæ•´æ–‡æœ¬
        self.buffer = ""

        self.state_path = state_path

    # ===== Callback API =====
    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:
        """æ”¶åˆ°æ–° token å°±å¢é‡åˆ·æ–° UIã€‚"""
        self._update(token)

    def on_llm_end(self, response, **kwargs: Any) -> None:
        """æµå¼ç»“æŸï¼ŒæŠŠå®Œæ•´å†…å®¹å†™è¿› session_stateã€‚"""
        if self.save:
            get_messages_container(self.state_path).append(
                {"role": self.role, "content": self.buffer}
            )

    # ===== ç§æœ‰ =====
    def _update(self, delta: str) -> None:
        if not delta:
            return
        self.buffer += delta

        # æ‹†åˆ† <think>
        think_parts = "\n".join(_THINK_RE.findall(self.buffer))
        answer_text = _THINK_RE.sub("", self.buffer).strip() or " "

        # ç¬¬ä¸€æ¬¡æ£€æµ‹åˆ° <think> â‡’ åˆ›å»º expander
        if think_parts and self.expander is None:
            self.expander = st.expander(self.label, expanded=False)
            self.think_holder = self.expander.empty()

        # åˆ·æ–° UI
        if self.think_holder is not None:
            self.think_holder.markdown(think_parts)
        self.answer_holder.markdown(answer_text)
