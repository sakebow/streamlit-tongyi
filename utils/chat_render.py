# handler.py
import re, time
import streamlit as st
from typing import Any
from collections.abc import Iterator

from langchain.callbacks.base import BaseCallbackHandler
from langchain_core.messages.base import BaseMessageChunk, BaseMessage

_THINK_RE = re.compile(r"<think>(.*?)</think>", re.S)

class ChatRenderer:
    """åŒæ—¶ç®¡ç† expander + chat_message çš„æµå¼æ¸²æŸ“å™¨"""

    def __init__(self, role: str, save: bool = True, typing_delay: float = 0.02):
        self.role          = role
        self.save          = save
        self.typing_delay  = typing_delay

        # UIï¼šå…ˆåªæ”¾ chat_messageï¼Œå ä½å¯åå¤å†™
        with st.chat_message(role):
            self.answer_holder = st.empty()

        # expander å»¶è¿Ÿåˆ›å»ºï¼ˆåªæœ‰æ£€æµ‹åˆ° <think> æ‰å»ºï¼‰
        self.expander      = None
        self.think_holder  = None

        # ç¼“å†²åŒº
        self._buffer = ""

    # ===== å¯¹å¤–å”¯ä¸€æ¥å£ =====
    def render(self, msg: "str | BaseMessage | Iterator[BaseMessageChunk]"):
        if isinstance(msg, str):
            self._update(msg)
        elif isinstance(msg, BaseMessage):
            self._update(msg.content)
        elif isinstance(msg, Iterator):
            for chunk in msg:
                self._update(chunk.content)
                time.sleep(self.typing_delay)
        else:
            raise TypeError("ä¸æ”¯æŒçš„æ¶ˆæ¯ç±»å‹")

        if self.save:
            st.session_state.dashscope["messages"].append(
                {"role": self.role, "content": self._buffer}
            )

    # ===== å†…éƒ¨ =====
    def _update(self, new_text: str):
        if not new_text:
            return
        self._buffer += new_text

        # æŠŠ <think> å‰¥ç¦»å‡ºæ¥
        think_parts = "\n".join(_THINK_RE.findall(self._buffer))
        answer_text = _THINK_RE.sub("", self._buffer).strip() or " "

        # === é¦–æ¬¡æ£€æµ‹åˆ° <think> â‡’ åŠ¨æ€åˆ›å»º expander ===
        if think_parts and self.expander is None:
            self.expander     = st.expander("ğŸ¤” æ€è€ƒè¿‡ç¨‹", expanded=False)
            self.think_holder = self.expander.empty()

        # åˆ·æ–° UI
        if self.think_holder is not None:
            self.think_holder.markdown(think_parts)
        self.answer_holder.markdown(answer_text)


# chat_render_callback
class ChatRenderCallbackHandler(BaseCallbackHandler):
    """æŠŠ LLM æµå¼ token æ¸²æŸ“åˆ° Streamlitï¼ŒåŒå®¹å™¨åˆ†æµã€‚"""

    def __init__(
        self,
        role: str = "assistant",
        save: bool = True,
        label: str = "ğŸ¤” æ€è€ƒè¿‡ç¨‹",
    ):
        super().__init__()
        self.role   = role
        self.save   = save
        self.label  = label

        # UI å ä½ï¼šåªæœ‰ answer å…ˆå ä½ï¼Œ<think> åŠ¨æ€ç”Ÿæˆ
        with st.chat_message(role):
            self.answer_holder = st.empty()

        self.expander     = None
        self.think_holder = None

        # ç´¯ç§¯å®Œæ•´æ–‡æœ¬
        self.buffer = ""

    # ===== Callback API =====
    def on_llm_new_token(self, token: str, **kwargs: Any) -> None:
        """æ”¶åˆ°æ–° token å°±å¢é‡åˆ·æ–° UIã€‚"""
        self._update(token)

    def on_llm_end(self, response, **kwargs: Any) -> None:
        """æµå¼ç»“æŸï¼ŒæŠŠå®Œæ•´å†…å®¹å†™è¿› session_stateã€‚"""
        if self.save:
            st.session_state.dashscope["messages"].append(
                {"role": self.role, "content": self.buffer}
            )

    # ===== ç§æœ‰ =====
    def _update(self, delta: str) -> None:
        if not delta:
            return
        self.buffer += delta

        # æ‹†åˆ† <think>
        think_parts = "\n".join(_THINK_RE.findall(self.buffer))
        answer_text = _THINK_RE.sub("", self.buffer).strip() or " "

        # ç¬¬ä¸€æ¬¡æ£€æµ‹åˆ° <think> â‡’ åˆ›å»º expander
        if think_parts and self.expander is None:
            self.expander     = st.expander(self.label, expanded=False)
            self.think_holder = self.expander.empty()

        # åˆ·æ–° UI
        if self.think_holder is not None:
            self.think_holder.markdown(think_parts)
        self.answer_holder.markdown(answer_text)
